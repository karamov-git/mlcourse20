{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_equal, assert_almost_equal\n",
    "from pandas.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) Энтропия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rule(x_train, y_train):\n",
    "    def entropy(y):\n",
    "        n = len(y)\n",
    "        p0 = len(y[y == 0]) / n\n",
    "        p1 = len(y[y == 1]) / n\n",
    "        if p0 == 0 or p1 == 0:  # when there is only one class in the group, entropy is 0\n",
    "            return 0\n",
    "        return -p0 * np.log2(p0) - p1 * np.log2(p1)\n",
    "\n",
    "    def ig(x_train, y_train, threshold):\n",
    "        group0 = y_train[x_train <= threshold]\n",
    "        group1 = y_train[x_train > threshold]\n",
    "        n = len(y_train)\n",
    "        n0 = len(group0)\n",
    "        n1 = len(group1)\n",
    "        return entropy(y_train) - (n0 / n) * entropy(group0) - (n1 / n) * entropy(group1)\n",
    "    \n",
    "    best_t = x_train[-1]\n",
    "    best_score = 0\n",
    "    for t in np.unique(x_train)[:-1]:\n",
    "        cur_score = ig(x_train, y_train, t)\n",
    "        if cur_score > best_score:\n",
    "            best_t = t\n",
    "            best_score = cur_score\n",
    "    return best_t, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDE (1) ID3 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3(Таблица примеров, Целевой признак, Признаки)\n",
    "\n",
    "    Если все примеры положительны, то возвратить узел с меткой «+».\n",
    "    Если все примеры отрицательны, то возвратить узел с меткой «-».\n",
    "    Если множество признаков пустое, то возвратить узел с меткой, которая больше других встречается в значениях целевого признака в примерах.\n",
    "    Иначе:\n",
    "        A — признак, который лучше всего классифицирует примеры (с максимальной информационной выгодой).\n",
    "        Создать корень дерева решения; признаком в корне будет являться A {\\displaystyle A} A.\n",
    "        Для каждого возможного значения A {\\displaystyle A} A ( v i {\\displaystyle v_{i}} v_{i}):\n",
    "            Добавить новую ветвь дерева ниже корня с узлом со значением A = v i {\\displaystyle A=v_{i}} A=v_{i}\n",
    "            Выделить подмножество E x a m p l e s ( v i ) {\\displaystyle Examples(v_{i})} Examples(v_{i}) примеров, у которых A = v i {\\displaystyle A=v_{i}} A=v_{i}.\n",
    "            Если подмножество примеров пусто, то ниже этой новой ветви добавить узел с меткой, которая больше других встречается в значениях целевого признака в примерах.\n",
    "            Иначе, ниже этой новой ветви добавить поддерево, вызывая рекурсивно ID3( E x a m p l e s ( v i ) {\\displaystyle Examples(v_{i})} Examples(v_{i}), Целевой признак, Признаки)\n",
    "    Возвратить корень."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class DecisionTreeClassifier(BaseEstimator):\n",
    "    def __init__(self, max_depth):\n",
    "        self.depth_ = 0\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, x, y, par_node={}, depth=0):\n",
    "    \"\"\"\n",
    "    x: Feature set\n",
    "    y: target variable\n",
    "    par_node: will be the tree generated for this x and y. \n",
    "    depth: the depth of the current layer\n",
    "    \"\"\"\n",
    "    if par_node is None:   # base case 1: tree stops at previous level\n",
    "        return None\n",
    "    elif len(y) == 0:   # base case 2: no data in this group\n",
    "        return None\n",
    "    elif self.all_same(y):   # base case 3: all y is the same in this group\n",
    "        return {'val':y[0]}\n",
    "    elif depth >= self.max_depth:   # base case 4: max depth reached \n",
    "        return None\n",
    "    else:   # Recursively generate trees! \n",
    "        # find one split given an information gain \n",
    "        col, cutoff, entropy = self.find_best_split_of_all(x, y)   \n",
    "        y_left = y[x[:, col] < cutoff]  # left hand side data\n",
    "        y_right = y[x[:, col] >= cutoff]  # right hand side data\n",
    "        par_node = {'col': iris.feature_names[col], 'index_col':col,\n",
    "                    'cutoff':cutoff,\n",
    "                   'val': np.round(np.mean(y))}  # save the information \n",
    "        # generate tree for the left hand side data\n",
    "        par_node['left'] = self.fit(x[x[:, col] < cutoff], y_left, {}, depth+1)   \n",
    "        # right hand side trees\n",
    "        par_node['right'] = self.fit(x[x[:, col] >= cutoff], y_right, {}, depth+1)  \n",
    "        self.depth += 1   # increase the depth since we call fit once\n",
    "        self.trees = par_node  \n",
    "        return par_node\n",
    "    \n",
    "def all_same(self, items):\n",
    "    return all(x == items[0] for x in items)\n",
    "    \n",
    "    def predict(X_test):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "model = DTC(criterion='entropy', max_depth=1).fit(x_train[:,np.newaxis], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.5, -2. , -2. ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tree_.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree_image(clf):\n",
    "    from sklearn.tree import export_graphviz\n",
    "    export_graphviz(clf, out_file='tree.dot', feature_names = ['x'],\n",
    "                    class_names = np.array(['0','1']),\n",
    "                    rounded = True, proportion = False, precision = 2, filled = True)\n",
    "    from subprocess import call\n",
    "    call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "    # Display in python\n",
    "    plt.figure(figsize = (9, 7))\n",
    "    plt.imshow(plt.imread('tree.png'))\n",
    "    plt.axis('off');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "create_tree_image(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.453877639491069e-14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0\n",
    "1e-15 * np.log(p + (1e-15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
